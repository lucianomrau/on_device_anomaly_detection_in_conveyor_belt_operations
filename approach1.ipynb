{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook corresponding to the \"Approach-1\" presented in the paper.\n",
    "\n",
    "This is the same approach used in the [\"Tinyml anomaly detection for industrial machines with periodic duty cycles\" (Sensor Application Symposium 2024)](https://ieeexplore.ieee.org/abstract/document/10636584/), and serves as the baseline experiment.\n",
    "\n",
    "Two experiments are carried on:\n",
    "1) As in the SAS2024, the performance is evaluated in leave-one-month-out CV in the original 4 months (called DS1).\n",
    "2) The generalization is evaluated using the whole DS1 for training and the whole DS2 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_functions import *\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data, extract feature and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different functions used in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"../../../data/\"\n",
    "#first 4 months of data (DS1)\n",
    "data_csv_jun21 = read_month_data(directory+'Confidential_Drive_data_Jun2021.csv',1)\n",
    "data_csv_okt21 = read_month_data(directory+'Confidential_Drive_data_Okt2021.csv',1)\n",
    "data_csv_jan22 = read_month_data(directory+'Confidential_Drive_data_Jan2022.csv',1)\n",
    "data_csv_april22 = read_month_data(directory+'Confidential_Drive_data_April2022.csv',1)\n",
    "#new 4 months (DS2)\n",
    "data_csv_jun23 = read_month_data(directory+'Confidential_Drive_data_June2023_Drift20.csv')\n",
    "data_csv_aug23 = read_month_data(directory+'Confidential_Drive_data_Aug2023_Drift20.csv')\n",
    "data_csv_okt23 = read_month_data(directory+'Confidential_Drive_data_Oct2023_Drift20.csv')\n",
    "data_csv_dec23 = read_month_data(directory+'Confidential_Drive_data_Dec2023_Drift20.csv')\n",
    "\n",
    "#re-order the column name to be consistent with the previous csv files\n",
    "desired_order=[\"High-pressure\",\"Low-pressure\",\"Speed\"]\n",
    "data_csv_jun23=data_csv_jun23[desired_order]\n",
    "data_csv_aug23=data_csv_aug23[desired_order]\n",
    "data_csv_okt23=data_csv_okt23[desired_order]\n",
    "data_csv_dec23=data_csv_dec23[desired_order]\n",
    "\n",
    "#These data has duplicated entries\n",
    "data_csv_okt23 = data_csv_okt23[~data_csv_okt23.index.duplicated(keep='first')]\n",
    "\n",
    "# round to zero speed less than zero\n",
    "data_csv_jun21.loc[data_csv_jun21['Speed'] < 0 , 'Speed'] = 0\n",
    "data_csv_okt21.loc[data_csv_okt21['Speed'] < 0 , 'Speed'] = 0\n",
    "data_csv_jan22.loc[data_csv_jan22['Speed'] < 0 , 'Speed'] = 0\n",
    "data_csv_april22.loc[data_csv_april22['Speed'] < 0 , 'Speed'] = 0\n",
    "data_csv_jun23.loc[data_csv_jun23['Speed'] < 0 , 'Speed'] = 0\n",
    "data_csv_aug23.loc[data_csv_aug23['Speed'] < 0 , 'Speed'] = 0\n",
    "data_csv_okt23.loc[data_csv_okt23['Speed'] < 0 , 'Speed'] = 0\n",
    "data_csv_dec23.loc[data_csv_dec23['Speed'] < 0 , 'Speed'] = 0\n",
    "\n",
    "\n",
    "# complete the dataset with missing values\n",
    "full_timestamp = pd.date_range(start = data_csv_jun21.index[0], end = data_csv_jun21.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_jun21 = data_csv_jun21.reindex(full_timestamp)\n",
    "\n",
    "full_timestamp = pd.date_range(start = data_csv_okt21.index[0], end = data_csv_okt21.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_okt21 = data_csv_okt21.reindex(full_timestamp)\n",
    "\n",
    "full_timestamp = pd.date_range(start = data_csv_jan22.index[0], end = data_csv_jan22.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_jan22 = data_csv_jan22.reindex(full_timestamp)\n",
    "\n",
    "full_timestamp = pd.date_range(start = data_csv_april22.index[0], end = data_csv_april22.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_april22 = data_csv_april22.reindex(full_timestamp)\n",
    "\n",
    "full_timestamp = pd.date_range(start = data_csv_jun23.index[0], end = data_csv_jun23.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_jun23 = data_csv_jun23.reindex(full_timestamp)\n",
    "\n",
    "full_timestamp = pd.date_range(start = data_csv_aug23.index[0], end = data_csv_aug23.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_aug23 = data_csv_aug23.reindex(full_timestamp)\n",
    "\n",
    "full_timestamp = pd.date_range(start = data_csv_okt23.index[0], end = data_csv_okt23.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_okt23 = data_csv_okt23.reindex(full_timestamp)\n",
    "\n",
    "full_timestamp = pd.date_range(start = data_csv_dec23.index[0], end = data_csv_dec23.index[-1],inclusive=\"both\",freq=\"1min\" )\n",
    "data_csv_dec23 = data_csv_dec23.reindex(full_timestamp)\n",
    "\n",
    "\n",
    "\n",
    "#use linear interpolation for the NaN missing values\n",
    "interpolate_values(data_csv_jun21)\n",
    "interpolate_values(data_csv_okt21)\n",
    "interpolate_values(data_csv_jan22)\n",
    "interpolate_values(data_csv_april22)\n",
    "interpolate_values(data_csv_jun23)\n",
    "interpolate_values(data_csv_aug23)\n",
    "interpolate_values(data_csv_okt23)\n",
    "interpolate_values(data_csv_dec23)\n",
    "\n",
    "del desired_order, directory, full_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_csv = [data_csv_jun21,data_csv_okt21,data_csv_jan22,data_csv_april22,data_csv_jun23,data_csv_aug23,data_csv_okt23,data_csv_dec23]\n",
    "for data in list_data_csv:\n",
    "    extract_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ground truth reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files from imagimob\n",
    "directory=\"../../data/\"\n",
    "column_interest=['Time(Seconds)' , 'Length(Seconds)',\"Label(string)\"]\n",
    "\n",
    "#read labels of states\n",
    "file_imagimob_1 = pd.read_csv(directory+\"April_2022/Label.label\",usecols=column_interest)\n",
    "file_imagimob_2 = pd.read_csv(directory+\"Jan_2022/Label.label\",usecols=column_interest)\n",
    "file_imagimob_3 = pd.read_csv(directory+\"Jun_2021/Label.label\",usecols=column_interest)\n",
    "file_imagimob_4 = pd.read_csv(directory+\"Okt_2021/Label.label\",usecols=column_interest)\n",
    "\n",
    "timestamps_april2022 = df_timestamps(file_imagimob_1)\n",
    "timestamps_jan2022 = df_timestamps(file_imagimob_2)\n",
    "timestamps_jun2021 = df_timestamps(file_imagimob_3)\n",
    "timestamps_okt2021 = df_timestamps(file_imagimob_4)\n",
    "\n",
    "#read labels of duty-cycle\n",
    "file_imagimob_1 = pd.read_csv(directory+\"April_2022/Label_cycle.label\",usecols=column_interest)\n",
    "file_imagimob_2 = pd.read_csv(directory+\"Jan_2022/Label_cycle.label\",usecols=column_interest)\n",
    "file_imagimob_3 = pd.read_csv(directory+\"Jun_2021/Label_cycle.label\",usecols=column_interest)\n",
    "file_imagimob_4 = pd.read_csv(directory+\"Okt_2021/Label_cycle.label\",usecols=column_interest)\n",
    "\n",
    "timestamps_cycle_april2022 = df_timestamps(file_imagimob_1)\n",
    "timestamps_cycle_jan2022 = df_timestamps(file_imagimob_2)\n",
    "timestamps_cycle_jun2021 = df_timestamps(file_imagimob_3)\n",
    "timestamps_cycle_okt2021 = df_timestamps(file_imagimob_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate vector with the labels of reference (states)\n",
    "downsampled_freq='1T'\n",
    "true_label_april22 = ndarray_labels(datetime.datetime(2022, 4, 1),datetime.datetime(2022, 5, 1),timestamps_april2022,downsampled_freq)\n",
    "true_label_jan22 = ndarray_labels(datetime.datetime(2021, 12, 21),datetime.datetime(2022, 1, 21),timestamps_jan2022,downsampled_freq)\n",
    "true_label_jun21 = ndarray_labels(datetime.datetime(2021, 6, 1),datetime.datetime(2021, 7, 1),timestamps_jun2021,downsampled_freq)\n",
    "true_label_okt21 = ndarray_labels(datetime.datetime(2021, 10, 1),datetime.datetime(2021, 11, 1),timestamps_okt2021,downsampled_freq)\n",
    "\n",
    "#generate vector with the labels of reference (duty-cycle)\n",
    "true_label_cycle_april22 = ndarray_labels(datetime.datetime(2022, 4, 1),datetime.datetime(2022, 5, 1),timestamps_cycle_april2022,downsampled_freq)\n",
    "true_label_cycle_jan22 = ndarray_labels(datetime.datetime(2021, 12, 21),datetime.datetime(2022, 1, 21),timestamps_cycle_jan2022,downsampled_freq)\n",
    "true_label_cycle_jun21 = ndarray_labels(datetime.datetime(2021, 6, 1),datetime.datetime(2021, 7, 1),timestamps_cycle_jun2021,downsampled_freq)\n",
    "true_label_cycle_okt21 = ndarray_labels(datetime.datetime(2021, 10, 1),datetime.datetime(2021, 11, 1),timestamps_cycle_okt2021,downsampled_freq)\n",
    "\n",
    "true_label_cycle_april22 = np.where(true_label_cycle_april22 == None, 'No_cycle', true_label_cycle_april22)\n",
    "true_label_cycle_jan22 = np.where(true_label_cycle_jan22 == None, 'No_cycle', true_label_cycle_jan22)\n",
    "true_label_cycle_jun21 = np.where(true_label_cycle_jun21 == None, 'No_cycle', true_label_cycle_jun21)\n",
    "true_label_cycle_okt21 = np.where(true_label_cycle_okt21 == None, 'No_cycle', true_label_cycle_okt21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imput ground-truth duty-cycle labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files from imagimob\n",
    "directory=\"../../data/\"\n",
    "#read labels of duty-cycle\n",
    "labels_jun21 = import_cycle_labels(directory+\"Jun_2021/Label_cycle.label\")\n",
    "labels_okt21 = import_cycle_labels(directory+\"Okt_2021/Label_cycle.label\")\n",
    "labels_jan22 = import_cycle_labels(directory+\"Jan_2022/Label_cycle.label\")\n",
    "labels_april22 = import_cycle_labels(directory+\"April_2022/Label_cycle.label\")\n",
    "labels_jun23 = import_cycle_labels(directory+\"June_23/Label_cycle.label\")\n",
    "labels_aug23 = import_cycle_labels(directory+\"Aug_23/Label_cycle.label\")\n",
    "labels_okt23 = import_cycle_labels(directory+\"Okt_23/Label_cycle.label\")\n",
    "labels_dec23 = import_cycle_labels(directory+\"Dec_23/Label_cycle.label\")\n",
    "\n",
    "\n",
    "for data in [labels_jun23,labels_aug23,labels_okt23,labels_dec23]:\n",
    "    replace_labels_cycles(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Data preparation and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label_jun21 [true_label_jun21=='E']='B'\n",
    "true_label_okt21 [true_label_okt21=='E']='B'\n",
    "true_label_jan22 [true_label_jan22=='E']='B'\n",
    "true_label_april22 [true_label_april22=='E']='B'\n",
    "\n",
    "data_DS1=[data_csv_jun21, data_csv_okt21,data_csv_jan22,data_csv_april22]\n",
    "data_DS2=[data_csv_jun23, data_csv_aug23,data_csv_okt23,data_csv_dec23]\n",
    "\n",
    "true_state_labels_DS1=[true_label_jun21, true_label_okt21,true_label_jan22,true_label_april22]\n",
    "df_testset_DS2= pd.concat(data_DS2)\n",
    "\n",
    "file_name_states_DS1= [\"jun2021_state.txt\" ,\"okt2021_state.txt\",\"jan2022_state.txt\",\"april2022_state.txt\"]\n",
    "file_name_cycles_DS1= [\"jun2021_cycle.txt\" ,\"okt2021_cycle.txt\",\"jan2022_cycle.txt\",\"april2022_cycle.txt\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "dir_exp1 = \"./results/approach1/DS1/\"\n",
    "dir_exp2 = \"./results/approach1/DS2/\"\n",
    "\n",
    "flag_save_results=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete not requires variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del timestamps_april2022, timestamps_jan2022, timestamps_jun2021, timestamps_okt2021\n",
    "del file_imagimob_1,file_imagimob_2,file_imagimob_3,file_imagimob_4, column_interest, directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Train/test on DS1 using leave-one-month CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds=list(range(0,10))\n",
    "classifiers=[\"rf\",\"dt\",\"xtree\",\"mlp\"]\n",
    "\n",
    "for i in range(len(data_DS1)):\n",
    "    # train_set\n",
    "    df_dataset = pd.concat([data for j, data in enumerate(data_DS1) if j != i])\n",
    "    df_dataset[\"ref_label\"]= np.concatenate([data for j, data in enumerate(true_state_labels_DS1) if j != i])\n",
    "\n",
    "    removed_indices = df_dataset[df_dataset['ref_label'].isnull()].index.tolist()\n",
    "    df_dataset = df_dataset[df_dataset['ref_label'].notnull()]\n",
    "    df_dataset=df_dataset.reset_index()\n",
    "\n",
    "    x_train = df_dataset[df_dataset.columns[1:-1]]\n",
    "    y_train = df_dataset[df_dataset.columns[-1]]\n",
    "    x_train_balanced, y_train_balanced, le = balance_dataset(x_train,y_train)\n",
    "    x_train_balanced=pd.DataFrame(scaler.fit_transform(x_train_balanced), columns=x_train.columns)\n",
    "    \n",
    "    #test_set\n",
    "    x_test=pd.DataFrame(scaler.fit_transform(data_DS1[i]), columns=x_train.columns)\n",
    "\n",
    "    for seed in seeds:\n",
    "        for classifier in classifiers:\n",
    "            #train/test states\n",
    "            clf = train_state_supervised_classifier(classifier,x_train_balanced, y_train_balanced,seed)\n",
    "            y_predict = clf.predict(x_test)\n",
    "\n",
    "            #apply 3rd median filter\n",
    "            y_pred_smoothed = smooth_labels(y_predict,3)\n",
    "            \n",
    "            y_recognized=le.inverse_transform(y_pred_smoothed.astype(int))\n",
    "            df_temp=data_DS1[i].copy()\n",
    "            df_temp[\"recognized_label\"]=y_recognized\n",
    "\n",
    "            # df_temp=df_testset.copy()\n",
    "            df_temp=df_temp.reset_index()\n",
    "\n",
    "            #classify duty-cycle\n",
    "            df_recognized_states = create_segments_state(data_DS1[i].index[0],data_DS1[i].index[-1],df_temp)\n",
    "            df_recognized_cycles = create_segments_cycles(df_recognized_states)\n",
    "\n",
    "            # save the results in files\n",
    "            if flag_save_results:\n",
    "                folder_path = dir_exp1+classifier+\"/\"+str(seed)+\"/\"\n",
    "                os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "                create_reference_label_file(folder_path+file_name_states_DS1[i],df_recognized_states)\n",
    "                create_reference_label_file(folder_path+file_name_cycles_DS1[i],df_recognized_cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "classifiers=[\"xgboost\",\"nb\"]\n",
    "\n",
    "for i in range(len(data_DS1)):\n",
    "    # train_set\n",
    "    df_dataset = pd.concat([data for j, data in enumerate(data_DS1) if j != i])\n",
    "    df_dataset[\"ref_label\"]= np.concatenate([data for j, data in enumerate(true_state_labels_DS1) if j != i])\n",
    "\n",
    "    removed_indices = df_dataset[df_dataset['ref_label'].isnull()].index.tolist()\n",
    "    df_dataset = df_dataset[df_dataset['ref_label'].notnull()]\n",
    "    df_dataset=df_dataset.reset_index()\n",
    "\n",
    "    x_train = df_dataset[df_dataset.columns[1:-1]]\n",
    "    y_train = df_dataset[df_dataset.columns[-1]]\n",
    "    x_train_balanced, y_train_balanced,le = balance_dataset(x_train,y_train)\n",
    "    x_train_balanced=pd.DataFrame(scaler.fit_transform(x_train_balanced), columns=x_train.columns)\n",
    "    \n",
    "    #test_set\n",
    "    x_test=pd.DataFrame(scaler.fit_transform(data_DS1[i]), columns=x_train.columns)\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        #train/test states\n",
    "        clf = train_state_supervised_classifier(classifier,x_train_balanced, y_train_balanced,seed)\n",
    "        y_predict = clf.predict(x_test)\n",
    "\n",
    "        #apply 3rd median filter\n",
    "        y_pred_smoothed = smooth_labels(y_predict,3)\n",
    "        \n",
    "        y_recognized=le.inverse_transform(y_pred_smoothed.astype(int))\n",
    "        df_temp=data_DS1[i].copy()\n",
    "        df_temp[\"recognized_label\"]=y_recognized\n",
    "\n",
    "        # df_temp=df_testset.copy()\n",
    "        df_temp=df_temp.reset_index()\n",
    "\n",
    "        #classify duty-cycle\n",
    "        df_recognized_states = create_segments_state(data_DS1[i].index[0],data_DS1[i].index[-1],df_temp)\n",
    "        df_recognized_cycles = create_segments_cycles(df_recognized_states)\n",
    "\n",
    "        # save the results in files\n",
    "        if flag_save_results:\n",
    "            folder_path = dir_exp1+classifier+\"/\"\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "            create_reference_label_file(folder_path+file_name_states_DS1[i],df_recognized_states)\n",
    "            create_reference_label_file(folder_path+file_name_cycles_DS1[i],df_recognized_cycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_exp1 = pd.DataFrame(columns=['state_classifier', \"detection mean\",'detection std',\n",
    "                                        'Abnormal mean F1-score','Abnormal std F1-score',\n",
    "                                        'Normal mean F1-score','Normal std F1-score',\n",
    "                                        'Overall mean F1-score','Overall std F1-score'])\n",
    "\n",
    "seeds=list(range(0,10))\n",
    "classifiers=[\"rf\",\"dt\",\"xtree\",\"mlp\"]\n",
    "\n",
    "dir = './results/reference_cycle_labels/'\n",
    "reference_path = dir\n",
    "collar = 202.75\n",
    "\n",
    "detection_files_abnormal, f1score_files_abnormal, precision_files_abnormal, recall_files_abnormal = [],[],[],[]\n",
    "detection_files_normal, f1score_files_normal, precision_files_normal, recall_files_normal = [],[],[],[]\n",
    "detection_files_overall, f1score_files_overall, precision_files_overall, recall_files_overall = [],[],[],[]\n",
    "\n",
    "for classifier_state in classifiers:\n",
    "    detection_files_abnormal, f1score_files_abnormal, precision_files_abnormal, recall_files_abnormal = [],[],[],[]\n",
    "    detection_files_normal, f1score_files_normal, precision_files_normal, recall_files_normal = [],[],[],[]\n",
    "    detection_files_overall, f1score_files_overall, precision_files_overall, recall_files_overall = [],[],[],[]\n",
    "\n",
    "    for seed_cycle in seeds:\n",
    "        result_path = dir_exp1+classifier_state+\"/\"+str(seed_cycle)+\"/\"\n",
    "        f1score_file, precision_file, recall_file, f1score_abnormal, precision_abnormal, recall_abnormal , f1score_normal, precision_normal, recall_normal= compute_classification_sedeval(reference_path,result_path,collar)\n",
    "        detection_file_overall = compute_detection_sedeval(reference_path,result_path,collar)\n",
    "        detection_files_overall.append(detection_file_overall)\n",
    "        f1score_files_overall.append(f1score_file)\n",
    "        precision_files_overall.append(precision_file)\n",
    "        recall_files_overall.append(recall_file)\n",
    "        f1score_files_abnormal.append(f1score_abnormal)\n",
    "        precision_files_abnormal.append(precision_abnormal)\n",
    "        recall_files_abnormal.append(recall_abnormal)\n",
    "        f1score_files_normal.append(f1score_normal)\n",
    "        precision_files_normal.append(precision_normal)\n",
    "        recall_files_normal.append(recall_normal)\n",
    "\n",
    "    print(\"---------- \"+classifier_state+\" ----------\")\n",
    "    print(\"DETECTION: \"+ str(np.mean(detection_files_overall)*100) +\" - \"+ str(np.std(detection_files_overall)*100) )\n",
    "    print(\"ABNORMAL:\")\n",
    "    print(\"F1-score: \"+ str(np.mean(f1score_files_abnormal)*100) +\" - \"+ str(np.std(f1score_files_abnormal)*100) )\n",
    "    print(\"Precision: \"+ str(np.mean(precision_files_abnormal)*100) +\" - \"+ str(np.std(precision_files_abnormal)*100) )\n",
    "    print(\"Recall: \"+ str(np.mean(recall_files_abnormal)*100) +\" - \"+ str(np.std(recall_files_abnormal)*100) )\n",
    "    print(\"NORMAL:\")\n",
    "    print(\"F1-score: \"+ str(np.mean(f1score_files_normal)*100) +\" - \"+ str(np.std(f1score_files_normal)*100) )\n",
    "    print(\"Precision: \"+ str(np.mean(precision_files_normal)*100) +\" - \"+ str(np.std(precision_files_normal)*100) )\n",
    "    print(\"Recall: \"+ str(np.mean(recall_files_normal)*100) +\" - \"+ str(np.std(recall_files_normal)*100) )\n",
    "    print(\"OVERALL:\")\n",
    "    print(\"F1-score: \"+ str(np.mean(f1score_files_overall)*100) +\" - \"+ str(np.std(f1score_files_overall)*100) )\n",
    "    print(\"Precision: \"+ str(np.mean(precision_files_overall)*100) +\" - \"+ str(np.std(precision_files_overall)*100) )\n",
    "    print(\"Recall: \"+ str(np.mean(recall_files_overall)*100) +\" - \"+ str(np.std(recall_files_overall)*100) )\n",
    "\n",
    "    dflocal = pd.DataFrame({'state_classifier':classifier_state, \n",
    "                            \"detection mean\": np.mean(detection_files_overall)*100,\n",
    "                            'detection std': np.std(detection_files_overall)*100,\n",
    "                            'Abnormal mean F1-score':np.mean(f1score_files_abnormal)*100,\n",
    "                            'Normal mean F1-score':np.mean(f1score_files_normal)*100,\n",
    "                            'Overall mean F1-score':np.mean(f1score_files_overall)*100,\n",
    "                            'Abnormal std F1-score':np.std(f1score_files_abnormal)*100,\n",
    "                            'Normal std F1-score':np.std(f1score_files_normal)*100,\n",
    "                            'Overall std F1-score':np.std(f1score_files_overall)*100},index=[0])\n",
    "        \n",
    "    df_results_exp1 = pd.concat([df_results_exp1, dflocal], ignore_index=True)\n",
    "\n",
    "classifiers=[\"xgboost\",\"nb\"]\n",
    "\n",
    "detection_files_abnormal, f1score_files_abnormal, precision_files_abnormal, recall_files_abnormal = [],[],[],[]\n",
    "detection_files_normal, f1score_files_normal, precision_files_normal, recall_files_normal = [],[],[],[]\n",
    "detection_files_overall, f1score_files_overall, precision_files_overall, recall_files_overall = [],[],[],[]\n",
    "\n",
    "for classifier_state in classifiers:\n",
    "    result_path = dir_exp1+classifier_state+\"/\"\n",
    "    f1score_file, precision_file, recall_file, f1score_abnormal, precision_abnormal, recall_abnormal , f1score_normal, precision_normal, recall_normal= compute_classification_sedeval(reference_path,result_path,collar)\n",
    "    detection_file_overall = compute_detection_sedeval(reference_path,result_path,collar)\n",
    "\n",
    "    print(\"---------- \"+classifier_state+\" ----------\")\n",
    "    print(\"DETECTION: \"+ str(detection_file_overall*100) )\n",
    "    print(\"ABNORMAL:\")\n",
    "    print(\"F1-score: \"+ str(f1score_abnormal*100) )\n",
    "    print(\"Precision: \"+ str(precision_abnormal*100) )\n",
    "    print(\"Recall: \"+ str(recall_abnormal*100) )\n",
    "    print(\"NORMAL:\")\n",
    "    print(\"F1-score: \"+ str(f1score_normal*100) )\n",
    "    print(\"Precision: \"+ str(precision_normal*100) )\n",
    "    print(\"Recall: \"+ str(recall_normal*100) )\n",
    "    print(\"OVERALL:\")\n",
    "    print(\"F1-score: \"+ str(f1score_file*100)  )\n",
    "    print(\"Precision: \"+ str(precision_file*100) )\n",
    "    print(\"Recall: \"+ str(recall_file*100) )\n",
    "\n",
    "    dflocal = pd.DataFrame({'state_classifier':classifier_state,\n",
    "                            \"detection mean\": np.mean(detection_file_overall)*100, \n",
    "                            'Abnormal mean F1-score':np.mean(f1score_abnormal)*100,\n",
    "                            'Normal mean F1-score':np.mean(f1score_normal)*100,\n",
    "                            'Overall mean F1-score':np.mean(f1score_file)*100},index=[0])\n",
    "        \n",
    "    df_results_exp1 = pd.concat([df_results_exp1, dflocal], ignore_index=True)\n",
    "\n",
    "df_results_exp1.to_csv(dir_exp1 + 'experiment1_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Train in DS1 and test in DS2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset= pd.concat([data_csv_jun21, data_csv_okt21,data_csv_jan22,data_csv_april22])\n",
    "df_dataset[\"ref_label\"]= np.concatenate((true_label_jun21, true_label_okt21,true_label_jan22,true_label_april22), axis=0)    \n",
    "df_dataset[\"ref_label_cycle\"]= np.concatenate((true_label_cycle_jun21, true_label_cycle_okt21,true_label_cycle_jan22,true_label_cycle_april22), axis=0)    \n",
    "\n",
    "removed_indices = df_dataset[df_dataset['ref_label'].isnull()].index.tolist()\n",
    "df_dataset = df_dataset[df_dataset['ref_label'].notnull()]\n",
    "df_dataset=df_dataset.reset_index()\n",
    "\n",
    "# remove the recognized_label column added in the experiment1\n",
    "if 'recognized_label' in df_dataset.columns:\n",
    "    df_dataset = df_dataset.drop('recognized_label', axis=1)\n",
    "\n",
    "x = df_dataset[df_dataset.columns[1:-2]]\n",
    "y_cycle = df_dataset[df_dataset.columns[-1]]\n",
    "y_state = df_dataset[df_dataset.columns[-2]]\n",
    "\n",
    "# normalize feature to range [0;1]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x,4)\n",
    "x = pd.DataFrame(scaler.transform(x), columns=x.columns)\n",
    "\n",
    "\n",
    "y_state [y_state=='E']='B'\n",
    "\n",
    "flag_save_results=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balance ds1 for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_balanced, y_train_balanced,le = balance_dataset(x,y_state)\n",
    "\n",
    "# Print balanced dataset\n",
    "unique_values, counts = np.unique(y_state, return_counts=True)\n",
    "value_counts = dict(zip(unique_values, counts))\n",
    "value_porcentages = dict(zip(unique_values, counts/sum(counts)*100))\n",
    "print(\"Value class-counts in Unbalanced dataset:\",value_counts)\n",
    "print(\"Value class-porcentage in Unbalanced dataset:\",value_porcentages)\n",
    "\n",
    "unique_values, counts = np.unique(y_train_balanced, return_counts=True)\n",
    "value_counts = dict(zip(unique_values, counts))\n",
    "value_porcentages = dict(zip(unique_values, counts/sum(counts)*100))\n",
    "print(\"Value class-counts in Balanced dataset:\",value_counts)\n",
    "print(\"Value class-porcentage in Balanced dataset:\",value_porcentages)\n",
    "\n",
    "del unique_values,counts,value_counts,value_porcentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data (DS2)\n",
    "df_testset= pd.concat([data_csv_jun23, data_csv_aug23,data_csv_okt23,data_csv_dec23])\n",
    "x_test = pd.DataFrame(scaler.transform(df_testset), columns=df_testset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds=list(range(0,10))\n",
    "classifiers=[\"rf\",\"dt\",\"xtree\",\"mlp\"]\n",
    "for seed in seeds:\n",
    "    for classifier in classifiers:\n",
    "        #train\n",
    "        clf = train_state_supervised_classifier(classifier,x_train_balanced, y_train_balanced,seed)\n",
    "\n",
    "        #test state-cycles\n",
    "        y_predict = clf.predict(x_test)\n",
    "\n",
    "        #apply 3rd median filter\n",
    "        y_pred_smoothed = smooth_labels(y_predict,3)\n",
    "        \n",
    "        y_recognized=le.inverse_transform(y_pred_smoothed.astype(int))\n",
    "        df_testset[\"recognized_label\"]=y_recognized\n",
    "\n",
    "        df_temp=df_testset.copy()\n",
    "        df_temp=df_temp.reset_index()\n",
    "\n",
    "        #classify duty-cycle\n",
    "        df_recognized_states_jun23 = create_segments_state(datetime.datetime(2023, 6, 1),datetime.datetime(2023, 7, 1),df_temp)\n",
    "        df_recognized_states_aug23 = create_segments_state(datetime.datetime(2023, 8, 1),datetime.datetime(2023, 9, 1),df_temp)\n",
    "        df_recognized_states_okt23 = create_segments_state(datetime.datetime(2023, 10, 1),datetime.datetime(2023, 11, 1),df_temp)\n",
    "        df_recognized_states_dec23 = create_segments_state(datetime.datetime(2023, 12, 1),datetime.datetime(2024, 1, 1),df_temp)\n",
    "\n",
    "        df_recognized_cycles_jun23 = create_segments_cycles(df_recognized_states_jun23)\n",
    "        df_recognized_cycles_aug23 = create_segments_cycles(df_recognized_states_aug23)\n",
    "        df_recognized_cycles_okt23 = create_segments_cycles(df_recognized_states_okt23)\n",
    "        df_recognized_cycles_dec23 = create_segments_cycles(df_recognized_states_dec23)\n",
    "\n",
    "        # save the results in files\n",
    "        if flag_save_results:\n",
    "            folder_path = dir_exp2+classifier+\"/\"+str(seed)\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "            create_reference_label_file(folder_path+\"/jun23_state.txt\",df_recognized_states_jun23)\n",
    "            create_reference_label_file(folder_path+\"/aug23_state.txt\",df_recognized_states_aug23)\n",
    "            create_reference_label_file(folder_path+\"/okt23_state.txt\",df_recognized_states_okt23)\n",
    "            create_reference_label_file(folder_path+\"/dec23_state.txt\",df_recognized_states_dec23)\n",
    "\n",
    "            create_reference_label_file(folder_path+\"/jun23_cycle.txt\",df_recognized_cycles_jun23)\n",
    "            create_reference_label_file(folder_path+\"/aug23_cycle.txt\",df_recognized_cycles_aug23)\n",
    "            create_reference_label_file(folder_path+\"/okt23_cycle.txt\",df_recognized_cycles_okt23)\n",
    "            create_reference_label_file(folder_path+\"/dec23_cycle.txt\",df_recognized_cycles_dec23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=[\"nb\",\"xgboost\"]\n",
    "for classifier in classifiers:\n",
    "    #train\n",
    "    clf = train_state_supervised_classifier(classifier,x_train_balanced, y_train_balanced,seed)\n",
    "\n",
    "    #test state-cycles\n",
    "    y_predict = clf.predict(x_test)\n",
    "\n",
    "    #apply 3rd median filter\n",
    "    y_pred_smoothed = smooth_labels(y_predict,3)\n",
    "    \n",
    "    y_recognized=le.inverse_transform(y_pred_smoothed.astype(int))\n",
    "    df_testset[\"recognized_label\"]=y_recognized\n",
    "\n",
    "    df_temp=df_testset.copy()\n",
    "    df_temp=df_temp.reset_index()\n",
    "\n",
    "    #classify duty-cycle\n",
    "    df_recognized_states_jun23 = create_segments_state(datetime.datetime(2023, 6, 1),datetime.datetime(2023, 7, 1),df_temp)\n",
    "    df_recognized_states_aug23 = create_segments_state(datetime.datetime(2023, 8, 1),datetime.datetime(2023, 9, 1),df_temp)\n",
    "    df_recognized_states_okt23 = create_segments_state(datetime.datetime(2023, 10, 1),datetime.datetime(2023, 11, 1),df_temp)\n",
    "    df_recognized_states_dec23 = create_segments_state(datetime.datetime(2023, 12, 1),datetime.datetime(2024, 1, 1),df_temp)\n",
    "\n",
    "    df_recognized_cycles_jun23 = create_segments_cycles(df_recognized_states_jun23)\n",
    "    df_recognized_cycles_aug23 = create_segments_cycles(df_recognized_states_aug23)\n",
    "    df_recognized_cycles_okt23 = create_segments_cycles(df_recognized_states_okt23)\n",
    "    df_recognized_cycles_dec23 = create_segments_cycles(df_recognized_states_dec23)\n",
    "\n",
    "    # save the results in files\n",
    "    if flag_save_results:\n",
    "        folder_path = dir_exp2+classifier\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        create_reference_label_file(folder_path+\"/jun23_state.txt\",df_recognized_states_jun23)\n",
    "        create_reference_label_file(folder_path+\"/aug23_state.txt\",df_recognized_states_aug23)\n",
    "        create_reference_label_file(folder_path+\"/okt23_state.txt\",df_recognized_states_okt23)\n",
    "        create_reference_label_file(folder_path+\"/dec23_state.txt\",df_recognized_states_dec23)\n",
    "\n",
    "        create_reference_label_file(folder_path+\"/jun23_cycle.txt\",df_recognized_cycles_jun23)\n",
    "        create_reference_label_file(folder_path+\"/aug23_cycle.txt\",df_recognized_cycles_aug23)\n",
    "        create_reference_label_file(folder_path+\"/okt23_cycle.txt\",df_recognized_cycles_okt23)\n",
    "        create_reference_label_file(folder_path+\"/dec23_cycle.txt\",df_recognized_cycles_dec23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_exp2 = pd.DataFrame(columns=['state_classifier', \"detection mean\",'detection std',\n",
    "                                        'Abnormal mean F1-score','Abnormal std F1-score',\n",
    "                                        'Normal mean F1-score','Normal std F1-score',\n",
    "                                        'Overall mean F1-score','Overall std F1-score'])\n",
    "\n",
    "seeds=list(range(0,10))\n",
    "classifiers=[\"rf\",\"dt\",\"xtree\",\"mlp\"]\n",
    "\n",
    "dir = './results/reference_cycle_labels/'\n",
    "reference_path = dir\n",
    "collar = 202.75\n",
    "\n",
    "detection_files_abnormal, f1score_files_abnormal, precision_files_abnormal, recall_files_abnormal = [],[],[],[]\n",
    "detection_files_normal, f1score_files_normal, precision_files_normal, recall_files_normal = [],[],[],[]\n",
    "detection_files_overall, f1score_files_overall, precision_files_overall, recall_files_overall = [],[],[],[]\n",
    "\n",
    "for classifier_state in classifiers:\n",
    "    detection_files_abnormal, f1score_files_abnormal, precision_files_abnormal, recall_files_abnormal = [],[],[],[]\n",
    "    detection_files_normal, f1score_files_normal, precision_files_normal, recall_files_normal = [],[],[],[]\n",
    "    detection_files_overall, f1score_files_overall, precision_files_overall, recall_files_overall = [],[],[],[]\n",
    "\n",
    "    for seed_cycle in seeds:\n",
    "        result_path = dir_exp2+classifier_state+\"/\"+str(seed_cycle)+\"/\"\n",
    "        f1score_file, precision_file, recall_file, f1score_abnormal, precision_abnormal, recall_abnormal , f1score_normal, precision_normal, recall_normal= compute_classification_sedeval(reference_path,result_path,collar)\n",
    "        detection_file_overall = compute_detection_sedeval(reference_path,result_path,collar)\n",
    "        detection_files_overall.append(detection_file_overall)\n",
    "        f1score_files_overall.append(f1score_file)\n",
    "        precision_files_overall.append(precision_file)\n",
    "        recall_files_overall.append(recall_file)\n",
    "        f1score_files_abnormal.append(f1score_abnormal)\n",
    "        precision_files_abnormal.append(precision_abnormal)\n",
    "        recall_files_abnormal.append(recall_abnormal)\n",
    "        f1score_files_normal.append(f1score_normal)\n",
    "        precision_files_normal.append(precision_normal)\n",
    "        recall_files_normal.append(recall_normal)\n",
    "\n",
    "    print(\"---------- \"+classifier_state+\" ----------\")\n",
    "    print(\"DETECTION: \"+ str(np.mean(detection_files_overall)*100) +\" - \"+ str(np.std(detection_files_overall)*100) )\n",
    "    print(\"ABNORMAL:\")\n",
    "    print(\"F1-score: \"+ str(np.mean(f1score_files_abnormal)*100) +\" - \"+ str(np.std(f1score_files_abnormal)*100) )\n",
    "    print(\"Precision: \"+ str(np.mean(precision_files_abnormal)*100) +\" - \"+ str(np.std(precision_files_abnormal)*100) )\n",
    "    print(\"Recall: \"+ str(np.mean(recall_files_abnormal)*100) +\" - \"+ str(np.std(recall_files_abnormal)*100) )\n",
    "    print(\"NORMAL:\")\n",
    "    print(\"F1-score: \"+ str(np.mean(f1score_files_normal)*100) +\" - \"+ str(np.std(f1score_files_normal)*100) )\n",
    "    print(\"Precision: \"+ str(np.mean(precision_files_normal)*100) +\" - \"+ str(np.std(precision_files_normal)*100) )\n",
    "    print(\"Recall: \"+ str(np.mean(recall_files_normal)*100) +\" - \"+ str(np.std(recall_files_normal)*100) )\n",
    "    print(\"OVERALL:\")\n",
    "    print(\"F1-score: \"+ str(np.mean(f1score_files_overall)*100) +\" - \"+ str(np.std(f1score_files_overall)*100) )\n",
    "    print(\"Precision: \"+ str(np.mean(precision_files_overall)*100) +\" - \"+ str(np.std(precision_files_overall)*100) )\n",
    "    print(\"Recall: \"+ str(np.mean(recall_files_overall)*100) +\" - \"+ str(np.std(recall_files_overall)*100) )\n",
    "\n",
    "    dflocal = pd.DataFrame({'state_classifier':classifier_state, \n",
    "                            \"detection mean\": np.mean(detection_files_overall)*100,\n",
    "                            'detection std': np.std(detection_files_overall)*100,\n",
    "                            'Abnormal mean F1-score':np.mean(f1score_files_abnormal)*100,\n",
    "                            'Normal mean F1-score':np.mean(f1score_files_normal)*100,\n",
    "                            'Overall mean F1-score':np.mean(f1score_files_overall)*100,\n",
    "                            'Abnormal std F1-score':np.std(f1score_files_abnormal)*100,\n",
    "                            'Normal std F1-score':np.std(f1score_files_normal)*100,\n",
    "                            'Overall std F1-score':np.std(f1score_files_overall)*100},index=[0])\n",
    "        \n",
    "    df_results_exp2 = pd.concat([df_results_exp2, dflocal], ignore_index=True)\n",
    "\n",
    "\n",
    "classifiers=[\"xgboost\",\"nb\"]\n",
    "\n",
    "detection_files_abnormal, f1score_files_abnormal, precision_files_abnormal, recall_files_abnormal = [],[],[],[]\n",
    "detection_files_normal, f1score_files_normal, precision_files_normal, recall_files_normal = [],[],[],[]\n",
    "detection_files_overall, f1score_files_overall, precision_files_overall, recall_files_overall = [],[],[],[]\n",
    "\n",
    "for classifier_state in classifiers:\n",
    "    result_path = dir_exp2+classifier_state+\"/\"\n",
    "    f1score_file, precision_file, recall_file, f1score_abnormal, precision_abnormal, recall_abnormal , f1score_normal, precision_normal, recall_normal= compute_classification_sedeval(reference_path,result_path,collar)\n",
    "    detection_file_overall = compute_detection_sedeval(reference_path,result_path,collar)\n",
    "\n",
    "    print(\"---------- \"+classifier_state+\" ----------\")\n",
    "    print(\"DETECTION: \"+ str(detection_file_overall*100) )\n",
    "    print(\"ABNORMAL:\")\n",
    "    print(\"F1-score: \"+ str(f1score_abnormal*100) )\n",
    "    print(\"Precision: \"+ str(precision_abnormal*100) )\n",
    "    print(\"Recall: \"+ str(recall_abnormal*100) )\n",
    "    print(\"NORMAL:\")\n",
    "    print(\"F1-score: \"+ str(f1score_normal*100) )\n",
    "    print(\"Precision: \"+ str(precision_normal*100) )\n",
    "    print(\"Recall: \"+ str(recall_normal*100) )\n",
    "    print(\"OVERALL:\")\n",
    "    print(\"F1-score: \"+ str(f1score_file*100)  )\n",
    "    print(\"Precision: \"+ str(precision_file*100) )\n",
    "    print(\"Recall: \"+ str(recall_file*100) )\n",
    "\n",
    "    dflocal = pd.DataFrame({'state_classifier':classifier_state,\n",
    "                            \"detection mean\": np.mean(detection_file_overall)*100, \n",
    "                            'Abnormal mean F1-score':np.mean(f1score_abnormal)*100,\n",
    "                            'Normal mean F1-score':np.mean(f1score_normal)*100,\n",
    "                            'Overall mean F1-score':np.mean(f1score_file)*100},index=[0])\n",
    "        \n",
    "    df_results_exp2 = pd.concat([df_results_exp2, dflocal], ignore_index=True)\n",
    "\n",
    "df_results_exp2.to_csv(dir_exp2 + 'experiment2_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
